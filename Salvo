#!/usr/bin/env perl
# Salvo
use strict;
use warnings qw(io);
use feature 'say';
use autodie;
use Getopt::Long;
use IO::Dir;
use File::Find;
use Cwd;

my $usage = <<"EOU";

Synopsis:

    Salvo - Slurm command and job launcher v 0.1.1

    ./Salvo -command_file <FILE> -account <STRING> -partition <STRING> -UID <STRING>
    ./Salvo -command_file <FILE> -account <STRING> -partition <STRING> -UID <STRING> -just_batch 

Description:

    Designed to aid launching of jobs on Slurm cluster from a command list file.
    View github page <https://github.com/srynobio/Salvo> for more detailed description.

Required options:

    -command_file, -cf      :   File containing list of commands to run. <FILE>
    -account, -a            :   CHPC account name. e.g. yandell-em. <STRING> 
    -partition, -p          :   CHPC partition to run jobs on. e.g. ember-freecycle <STRING>
    -UID                    :   Your University or employee id. <STRING> 

Additional options:

    -time, -t               :   Time to allow each job to run on node <STRING> (default 1:00:00).
    -node, -n               :   Number of nodes to run per sbatch job submitted. <INT> default 1).
    -queue_limit, -ql       :   Number of jobs to launch and run in the queue at one time. <INT> (default 1).
    -jobs_per_sbatch, -jps  :   Number of jobs to run concurrently, & added to each command. <INT> (default 1);
    -added_steps, -as       :   Additional step to add to each sbatch job <STRING> (comma separated).
    -just_sbatch            :   This option will create all sbatch jobs die, but not submit them (default FALSE).
    -chdir                  :   This option will tell each sbatch job to cd into this directory before running command. <STRING> (default current).
    -clean                  :   Option will remove launch.index, *sbatch and *out jobs.
    -help                   :   Prints this battleworn help message.

EOU

my %salvo_opts;
GetOptions(
    \%salvo_opts,
    "commands_file|cf=s",
    "jobs_per_sbatch|jps=i",
    "time|t=s",
    "nodes|n=i",
    "account|a=s",
    "partition|p=s",
    "queue_limit|ql=i",
    "clean",
    "just_sbatch",
    "added_steps|as=s",
    "chdir=s",
    "UID=s",
    "help|h",
);

## Just run clean up.
if ( $salvo_opts{clean} ) { 
    `rm *out *sbatch launch.index`;
    say "Cleaned up!";
    exit(0);
}

## Require check
unless ( 
    $salvo_opts{commands_file} and $salvo_opts{account} and $salvo_opts{partition} and $salvo_opts{UID} ) {
    die "$usage\n[ERROR] - Options command_file, account, UID and partition required.";
}

## clean up old sbatch scripts.
say "Looking for and removing any prior sbatch scripts";
my @found_sbatch = `find . -name \"*sbatch\"`;
chomp @found_sbatch;
if ( @found_sbatch ) {
    say "removing found sbatch scripts";
    map { `rm $_` } @found_sbatch;
}

## set up some defaults.
$salvo_opts{jobs_per_sbatch} //= 1;
$salvo_opts{time} //= '1:00:00';
$salvo_opts{nodes} //= 1;
$salvo_opts{queue_limit} //= 1;

## if step were added get them ready.
my @steps;
if ($salvo_opts{added_steps}) {
    if ($salvo_opts{added_steps} =~ /\,/) {
        @steps = split /\,/, $salvo_opts{added_steps};
    }
    else {
        push @steps, $salvo_opts{added_steps};
    }
}

## Get the supplied dir or the current working.
my $dir = (($salvo_opts{chdir}) ? $salvo_opts{chdir} : getcwd);

## open command file
my $CMDS = IO::File->new($salvo_opts{commands_file});

my @cmds;
foreach my $cmd (<$CMDS>) {
    chomp $cmd;
    $cmd =~ s/$/ &/ if ($salvo_opts{jobs_per_sbatch} > 1);
    push @cmds, $cmd;
}
$CMDS->close;

## split base on jps, then create sbatch scripts.
my @var;
push @var, [ splice @cmds, 0, $salvo_opts{jobs_per_sbatch} ] while @cmds;

my $jobid = 1;
foreach my $group (@var) {
    chomp $group;
    $jobid++;
    writer($group, $jobid);
}

## just create sbatch jobs dont submit.
die "[WARN] - sbatch scripts written but not submitted\n" if ($salvo_opts{just_sbatch});

## Review total sbatch to launch.
my @total  = glob "*sbatch";
chomp @total;
my $number_of_jobs = scalar @total;
say "[WARN]  - sbatch submission total: $number_of_jobs";
say "[INPUT] - continue? [y/n]";
my $continue = <STDIN>;
chomp $continue;
($continue eq 'y') ? say "Salvo running..." : exit(0);

## submit sbatch jobs.
my $DIR = IO::Dir->new(".");
my $running = 0;
foreach my $launch ($DIR->read) {
    chomp $launch;
    next unless ( $launch =~ /sbatch$/);

    if ( $running >= $salvo_opts{queue_limit} ) {
        my $status = _jobs_status();
        if ( $status eq 'add' ) {
            $running--;
            redo;
        }
        elsif ( $status eq 'wait' ) {
            sleep(10);
            redo;
        }
    }
    else {
        system "sbatch $launch &>> launch.index";
        $running++;
        next;
    }
}

# give sbatch system time to work
sleep(10);

# check the status of current sbatch jobs
# before moving on.

_wait_all_jobs();
_error_check();
unlink('launch.index');

## --------------------------------------------------- ##

sub _jobs_status {
    my $state = `squeue -A $salvo_opts{partition} -u u0413537 -h | wc -l`;

    if ( $state >= $salvo_opts{queue_limit} ) {
        return 'wait';
    }
    else {
        return 'add';
    }
}

## --------------------------------------------------- ##

sub _wait_all_jobs {

    my $process;
    do {
        sleep(60);
        _relaunch();
        sleep(60);
        $process = _process_check();
    } while ($process);
}

## --------------------------------------------------- ##

sub _relaunch {
    my @error = `grep error *.out`;
    chomp @error;
    if ( !@error ) { return }

    my %relaunch;
    my @error_files;
    foreach my $cxl (@error) {
        chomp $cxl;

        if ( $cxl =~ /TIME LIMIT/ ) {
            say "[WARN] a job was canceled due to time time limit";
            next;
        };

        next unless ( $cxl =~ /PREEMPTION/ );

        my @ids = split /\s/, $cxl;

        ## collect error files.
        my ( $sbatch, undef ) = split /:/, $ids[0];
        push @error_files, $sbatch;

        ## record launch id.
        $relaunch{ $ids[4] }++;
    }

    open( my $FH, '>>', 'launch.index' );

    my @indexs = `cat launch.index`;
    chomp @indexs;

    foreach my $line (@indexs) {
        chomp $line;
        my @parts = split /\s/, $line;

        ## find in lookup and dont re-relaunch.
        if ( $relaunch{ $parts[-1] } ) {
            print $FH "$parts[0]\t";
            system "sbatch $parts[0] >> launch.index";
            say "[WARN] Relaunching job $parts[0]";
        }
    }
    ## remove error files.
    unlink @error_files;
}

## --------------------------------------------------- ##

sub _process_check {

    my @processing = `squeue -A $salvo_opts{account} -u u0413537 -h --format=%A`;
    chomp @processing;
    if ( !@processing ) { return 0 }

    ## check run specific processing.
    ## make lookup of what is running.
    my %running;
    foreach my $active ( @processing ) {
        chomp $active;
        $active =~ s/\s+//g;
        $running{$active}++;
    }

    ## check what was launched.
    open(my $LAUNCH, '<', 'launch.index') or die "[ERROR] Can't find needed launch.index file.";

    my $current = 0;
    foreach my $launched ( <$LAUNCH> ) {
        chomp $launched;
        my @result = split /\s+/, $launched;

        if ( $running{$result[-1]} ) {
            $current++;
        }
    }
    ($current) ? (return 1) : (return 0);
}

## --------------------------------------------------- ##

sub _error_check {
    my @error = `grep error *.out`;
    if ( !@error ) { return }

    say "[WARN] errors were found in salvo output files";
}

## --------------------------------------------------- ##

sub writer {
    my ($stack, $jobid) = @_;

    my $jobname = 'salvo-' . $jobid;
    my $slurm_out = $jobname . '.out';
    my $outfile = $jobname . '.sbatch';

    my $cmds = join("\n", @{$stack} );
    my $extra_steps = join("\n", @steps) if @steps;

    my $sbatch = <<"EOM";
#!/bin/bash
#SBATCH -t $salvo_opts{time}
#SBATCH -N $salvo_opts{nodes}
#SBATCH -A $salvo_opts{account}
#SBATCH -p $salvo_opts{partition}
#SBATCH -J $jobname
#SBATCH -o $slurm_out

cd $dir

$extra_steps

$cmds

wait

EOM

open(my $OUT, '>', $outfile);
say $OUT $sbatch;

close $OUT;
}

## --------------------------------------------------- ##

